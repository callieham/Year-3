{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY98Oclcl92-"
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "Naive Bayes is a classification algorithm based on Bayes' theorem. Bayes’ theorem provides a way to calculate the probability of a data point belonging to a given class, given our prior knowledge. It is defined as\n",
        "\n",
        "$$\n",
        "\\mathbb P (class|data) = \\frac{\\mathbb P (data|class) \\ \\mathbb P (class)}{\\mathbb P (data)} ,\n",
        "$$\n",
        "\n",
        "where $\\mathbb P (class | data)$ is the aprobability over the potential classes given the provided data. The different probabilities $\\mathbb P$ you see in the equations above are commonly called prior, likelihood, evidence, and posterior as follows.\n",
        "\n",
        "$$\n",
        "\\overbrace{\\mathbb P (class|data)}^{\\text{posterior}} = \\frac{\\overbrace{\\mathbb P (data|class)}^{\\text{likelihood}} \\ \\overbrace{\\mathbb P (class)}^{\\text{prior}}}{\\underbrace{\\mathbb P (data)}_{\\text{evidence}}}\n",
        "$$\n",
        "\n",
        "The algorithm is called 'naive', because of its assumption that features of data are independent given the class label. Let us call the data features $x_1, \\dots, x_i, \\dots, x_p$ and the class label $y$, and rewrite Bayes theorem in these terms:\n",
        "\n",
        "$$\n",
        "\\mathbb P (y|x_1, \\dots, x_p) = \\frac{\\mathbb P (x_1, \\dots, x_p|y) * \\mathbb P (y)}{\\mathbb P (x_1, \\dots, x_p)} \\, .\n",
        "$$\n",
        "\n",
        "Then, the naive assumption of conditional independence between any two features given the class label can be expressed as\n",
        "\n",
        "$$\n",
        "\\mathbb P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_p) = \\mathbb P (x_i | y) \\, ,\n",
        "$$\n",
        "\n",
        "and now Bayes' theorem leads to:\n",
        "\n",
        "$$\n",
        "\\mathbb P (y | x_1, \\dots, x_p) = \\frac{\\mathbb P (y) \\prod_{i=1}^p \\mathbb P(x_i | y)}{\\mathbb P (x_1, \\dots, x_p)} \\, .\n",
        "$$\n",
        "\n",
        "Since $\\mathbb P (x_1, \\dots, x_p)$ is the constant input, we can define the following proportional relationship\n",
        "\n",
        "$$\n",
        "\\mathbb P (y|x_1, \\dots, x_p) \\propto \\mathbb P (y) \\prod_{i=1}^p \\mathbb P(x_i | y) \\, ,\n",
        "$$\n",
        "\n",
        "and can use it to classify any data point as\n",
        "\n",
        "$$\n",
        "\\hat y = \\underset{y}{\\text{arg max}} \\ \\mathbb P (y) \\prod_{i=1}^p \\mathbb P(x_i | y) \\, .\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data for text classification\n",
        "\n",
        "To learn how this algorithm works in practice, we define a simple data set of emails being either spam or not (adopted from Chapter 3.5, Exercise 3.22 in Machine Learning: A Probabilistic Perspective by Murphy). _Note that Naive Bayes can indeed be used for multiclass classification, however we use it here as a binary classifier._\n",
        "\n",
        "We will work with the packages numpy and pandas, but also make our lives a bit easier with sklearn's implemented feature extractor to count words and its validation module to check whether data arrives in the format we need it."
      ],
      "metadata": {
        "id": "p0UPRbx3QVN_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r_Xo0HklZFx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Callable\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.utils.validation import check_X_y, check_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following Murphy, we create a toy dataset for spam email classification."
      ],
      "metadata": {
        "id": "t4XxAWOYIdpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define vocabulary\n",
        "vocab = [\n",
        "        'secret', 'offer', 'low', 'price', 'valued', 'customer', 'today',\n",
        "        'dollar', 'million', 'sports', 'is', 'for', 'play', 'healthy', 'pizza'\n",
        "    ]\n",
        "\n",
        "# define train spam emails\n",
        "spam = [\n",
        "    'million dollar offer',\n",
        "    'secret offer today',\n",
        "    'secret is secret'\n",
        "]\n",
        "\n",
        "# define train non-spam emails\n",
        "not_spam = [\n",
        "    'low price for valued customer',\n",
        "    'play secret sports today',\n",
        "    'sports is healthy',\n",
        "    'low price pizza'\n",
        "]"
      ],
      "metadata": {
        "id": "cq-2Xo5qIZzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to bring the toy data into a numerical form fit for applying machine learning models. We define the input variable $X$ as a [*document-term matrix*](https://en.wikipedia.org/wiki/Document-term_matrix), which counts the frequency of words in each document, and $y$ is the binary target variable that encodes whether a document is spam (1) or not (0). The document-term matrix $X$ is a standard data format in natural language processing (NLP) used in the *bag-of-words model*, where each document is represented by a vector that encodes the frequency of appearing words."
      ],
      "metadata": {
        "id": "uUNsknX9IvVN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbwhd07rsZxv"
      },
      "source": [
        "def prepare_spam_dataset(vocab, spam, not_spam, show_X=True):\n",
        "    \"\"\" Prepare spam toy dataset for MultinomialNB implementation.\n",
        "\n",
        "    Returns:\n",
        "        X: word count matrix\n",
        "        y: indicator of whether or not message is spam\n",
        "    \"\"\"\n",
        "\n",
        "    # corpus consists of spam and non-spam documents\n",
        "    all_messages = spam + not_spam\n",
        "\n",
        "    # compute document-term matrix\n",
        "    vectorizer = CountVectorizer(vocabulary=vocab)\n",
        "    word_counts = vectorizer.fit_transform(all_messages).toarray()\n",
        "    df = pd.DataFrame(word_counts, columns=vocab)\n",
        "\n",
        "    # encode class of each document\n",
        "    is_spam = [1] * len(spam) + [0] * len(not_spam)  # storing our labels in a list (1 means spam email, 0 means no spam email)\n",
        "\n",
        "    if show_X:\n",
        "        display(df)\n",
        "\n",
        "    return df.to_numpy(), np.array(is_spam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "LAF17qr2sv9G",
        "outputId": "a1dcfacf-0d34-4318-a753-8d91a535ce17"
      },
      "source": [
        "# define our variables and print document-term matrix X\n",
        "X, y = prepare_spam_dataset(vocab, spam, not_spam, show_X=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   secret  offer  low  price  valued  customer  today  dollar  million  \\\n",
              "0       0      1    0      0       0         0      0       1        1   \n",
              "1       1      1    0      0       0         0      1       0        0   \n",
              "2       2      0    0      0       0         0      0       0        0   \n",
              "3       0      0    1      1       1         1      0       0        0   \n",
              "4       1      0    0      0       0         0      1       0        0   \n",
              "5       0      0    0      0       0         0      0       0        0   \n",
              "6       0      0    1      1       0         0      0       0        0   \n",
              "\n",
              "   sports  is  for  play  healthy  pizza  \n",
              "0       0   0    0     0        0      0  \n",
              "1       0   0    0     0        0      0  \n",
              "2       0   1    0     0        0      0  \n",
              "3       0   0    1     0        0      0  \n",
              "4       1   0    0     1        0      0  \n",
              "5       1   1    0     0        1      0  \n",
              "6       0   0    0     0        0      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7995a2c4-4957-4b3e-a5e8-57d399a680bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>secret</th>\n",
              "      <th>offer</th>\n",
              "      <th>low</th>\n",
              "      <th>price</th>\n",
              "      <th>valued</th>\n",
              "      <th>customer</th>\n",
              "      <th>today</th>\n",
              "      <th>dollar</th>\n",
              "      <th>million</th>\n",
              "      <th>sports</th>\n",
              "      <th>is</th>\n",
              "      <th>for</th>\n",
              "      <th>play</th>\n",
              "      <th>healthy</th>\n",
              "      <th>pizza</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7995a2c4-4957-4b3e-a5e8-57d399a680bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7995a2c4-4957-4b3e-a5e8-57d399a680bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7995a2c4-4957-4b3e-a5e8-57d399a680bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33eb0c1f-06df-45ff-8944-a60151848c80\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33eb0c1f-06df-45ff-8944-a60151848c80')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33eb0c1f-06df-45ff-8944-a60151848c80 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking at the document-term matrix $X$ one can already recognize some patterns in the relationship between words and spam. For example, the word secret appears three times in spam emails (the first three rows) but only one time in non-spam documents (the last four rows)."
      ],
      "metadata": {
        "id": "w3S8-GM0MCFx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KReuBEwe1hye"
      },
      "source": [
        "## Likelihood in Multinomial Naive Bayes\n",
        "\n",
        "Next, we train the Naive Bayes classifier with a `train` function where we define the prior. Recall from our lectures that the prior is the probability distribution incorporating our knowledge of the classes (here spam and not-spam) and it can be directly computed from $y$ using equation (5.2) from the lecture notes. We then separate the training examples of both classes and denote the document-term matrix of documents in class $y$ as $X_y$. Using these ingredients you can then compute the likelihood of a word appearing in a document given its class (spam or not-spam) under the assumption of multinomiallly distributed data and we also apply *Laplace smoothing* to avoid zero probabilities. In particular, the probability $\\mathbb P(x_i|y)$ of term $i\\in{1,2,...,p}$ appearing in a document of class $y$ is given by:\n",
        "\n",
        "$$\n",
        "\\mathbb P(x_i|y) = \\frac{ N_{yi} + 1}{N_y + p},\n",
        "$$\n",
        "\n",
        "where $N_{yi} = \\sum_{x \\in X_y} x_i$ is the number of times term $i$ appears in a document of class $y$ in the training set, and $N_{y} = \\sum_{i=1}^{p} N_{yi}$ is the total count of all features for class $y$. This version of the Naive Bayes classifier is also called [*Multinomial Naive Bayes*](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq5Bwv4h1hZk"
      },
      "source": [
        "# EDIT THIS FUNCTION\n",
        "def fit(X, y):\n",
        "    \"\"\" Use training data to fit Naive Bayes classifier.\n",
        "\n",
        "    Parameters:\n",
        "      X (np.array): Features\n",
        "      y (np.array): Categorical target\n",
        "\n",
        "    Returns:\n",
        "      prior (np.array): Prior distribution of classes\n",
        "      lk_word (np.array): Likelihood of words (features) to appear given class\n",
        "    \"\"\"\n",
        "\n",
        "    # not strictly necessary, but this ensures we have clean input\n",
        "    X, y = check_X_y(X, y)\n",
        "    p = X.shape[1]\n",
        "\n",
        "    # define prior\n",
        "    prior = # <-- EDIT THIS LINE\n",
        "\n",
        "    # reorder X as a 2-dimensional array; each dimension contains data examples of only one of our two classes\n",
        "    X_by_class = [X[y==c] for c in np.unique(y)]\n",
        "\n",
        "    # count words in each class\n",
        "    word_counts = np.array([X_c.sum(axis=0) for X_c in X_by_class])\n",
        "\n",
        "    # define likelihood P(x|y) using Laplace smoothing, shape: (Nc, n)\n",
        "    lk_word = # <-- EDIT THIS LINE\n",
        "\n",
        "    return prior, lk_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call function and print prior\n",
        "prior, lk_word = fit(X, y)\n",
        "print('Prior:', prior)\n",
        "print('\\n----------------')\n",
        "print('Likelihood that word is typical for not_spam: \\n', lk_word[0])\n",
        "print('\\n----------------')\n",
        "print('Likelihood that word is typical for spam: \\n', lk_word[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0wif-RB82zs",
        "outputId": "b8ccff0d-5d0c-4922-a420-ec33a399e6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior: [0.57142857 0.42857143]\n",
            "\n",
            "----------------\n",
            "Likelihood that word is typical for not_spam: \n",
            " [0.06666667 0.03333333 0.1        0.1        0.06666667 0.06666667\n",
            " 0.06666667 0.03333333 0.03333333 0.1        0.06666667 0.06666667\n",
            " 0.06666667 0.06666667 0.06666667]\n",
            "\n",
            "----------------\n",
            "Likelihood that word is typical for spam: \n",
            " [0.16666667 0.125      0.04166667 0.04166667 0.04166667 0.04166667\n",
            " 0.08333333 0.08333333 0.08333333 0.04166667 0.08333333 0.04166667\n",
            " 0.04166667 0.04166667 0.04166667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Questions:\n",
        "1. What is the meaning of the likelihood $\\mathbb P(x_i|y)$ in the context of our toy example?\n",
        "2. Plot the likelihood $\\mathbb P(x_i|y)$ of each word $i$ given the different classes and explain where the difference comes from."
      ],
      "metadata": {
        "id": "29-oXoDURy6V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPfkKXvk7oyC"
      },
      "source": [
        "## Posterior in Multinomial Naive Bayes\n",
        "\n",
        "Now we can predict whether any given email is spam or not. To do so we compute the posterior probability $\\mathbb P(y|x)$ that a document $x$ is part of class $y$ following equation (5.6). In the context of Multinomial Naive Bayes, the posterior is given by:\n",
        "\n",
        "$$\n",
        "\\mathbb P(y|x) \\propto \\mathbb P(y) ∏_{i=1}^p \\mathbb P(x_i|y)^{x_i}\n",
        "$$\n",
        "\n",
        "As multiplication of many small values can lead to significant rounding errors, it's advantagous to carry out this computation in log space:\n",
        "\n",
        "$$\n",
        "\\log \\mathbb P(y|x) \\propto \\log \\mathbb P(y) + \\sum_{i=1}^p x_i \\, \\log \\mathbb P(x_i|y)\n",
        "$$\n",
        "\n",
        "Note that the log-posterior is linear. We now implement a function that calculates the log-posterior using linear algebra and then returns the normalized (!) posterior probabilities."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EDIT THIS FUNCTION\n",
        "def predict_proba(X, prior, lk_word):\n",
        "    \"\"\" Predict probability of class with Naive Bayes.\n",
        "\n",
        "    Params:\n",
        "      X (np.array): Features\n",
        "      prior (np.array): Prior distribution of classes\n",
        "      lk_word (np.array): Likelihood of words (features) to appear given class\n",
        "\n",
        "    Returns:\n",
        "      posteriors (np.array): Posterior distribution of documents\n",
        "    \"\"\"\n",
        "\n",
        "    # compute log-posterior\n",
        "    # <-- EDIT THIS LINE\n",
        "\n",
        "    # normalize to get full posterior distribution\n",
        "    # <-- EDIT THIS LINE\n",
        "\n",
        "    return posteriors"
      ],
      "metadata": {
        "id": "KhsW-W6RMyrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now compute the posterior probabilities for our training data."
      ],
      "metadata": {
        "id": "vVQvpaDLN2p9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ViH8LlA1hNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a94b99c-16f2-4ee8-f872-93f78cec54b2"
      },
      "source": [
        "# compute full posterior distribution\n",
        "posteriors = predict_proba(X, prior, lk_word)\n",
        "print(\"Posteriors:\\n\", posteriors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posteriors:\n",
            " [[0.05382675 0.94617325]\n",
            " [0.10215483 0.89784517]\n",
            " [0.14578588 0.85421412]\n",
            " [0.96919027 0.03080973]\n",
            " [0.62098241 0.37901759]\n",
            " [0.80376766 0.19623234]\n",
            " [0.92474413 0.07525587]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUJxJ9h6C4g_"
      },
      "source": [
        "Finally, we can classify the documents in a binary fashion by asserting any data points $X$ to the class $y$ with the highest probability (called the *argmax choice*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36IsDfzH1eXN"
      },
      "source": [
        "# EDIT THIS FUNCTION\n",
        "def predict(X, prior, lk_word):\n",
        "    \"\"\" Predict class with highest probability.\n",
        "\n",
        "    Params:\n",
        "      X (np.array): Features\n",
        "      prior (np.array): Prior distribution of classes\n",
        "      lk_word (np.array): Likelihood of words (features) to appear given class\n",
        "\n",
        "    Returns:\n",
        "      y_pred (np.array): Predicted target\n",
        "    \"\"\"\n",
        "\n",
        "    # prediction given by argmax choice\n",
        "    # <-- EDIT THIS LINE\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we take the same emails we used for training our Naive Bayes classifier to also to evaluate it. Usually, the evaluation happens on unseen emails (test data) and it is your task below to define a small test dataset. What are the predicted classes and what is the accuracy of the classifier?"
      ],
      "metadata": {
        "id": "x4skIf2h4szZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FroLvChb1hKg",
        "outputId": "dc62683d-ee53-4b34-cf70-39a35b5a3583"
      },
      "source": [
        "# predict targets for training data with Naive Bayes\n",
        "# <-- EDIT THIS LINE\n",
        "# <-- EDIT THIS LINE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes:  [1 1 1 0 0 0 0]\n",
            "Train accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHJr2ZflEFGp"
      },
      "source": [
        "#### Questions:\n",
        "1. Define your own three short emails as a test set and evaluate our Naive Bayes classifier on it without re-training it on them. What do you observe?\n",
        "2. What words have you included in emails of the test set that make them being classified as spam or not spam?\n",
        "3. Can you replicate your results using [sklearn](https://scikit-learn.org/stable/modules/naive_bayes.html)?\n",
        "4. Based on sklearn's documentation, can you see any differences in the algorithms that are implemented in sklearn?"
      ]
    }
  ]
}